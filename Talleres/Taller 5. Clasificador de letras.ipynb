{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Usando el dataset de iris cargue el conjunto de entrenamiento (X) y las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat('Datasets/dataFI.mat')\n",
    "data = np.array(list(data.values()))\n",
    "X=data[3]\n",
    "t=data[4]\n",
    "t= np.argmax(t, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- Siga los siguientes pasos (2.5):\n",
    "\n",
    "* Use Normalizer para normalizar el conjunto de entrenamiento <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html\">Ver</a>.\n",
    "* Use train_test_split para armar el conjunto de entrenamiento y el conjunto de pruebas. Use 70% para entrenar y 30% para pruebas <a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#\">Ver</a>.\n",
    "* Use una red neuronal que tenga como solver un gradiente descendiente estocástico (sgd) y como función de activación (activation) la función logística (logistic). Defina los demás hiperparámetros para ajustar el entrenamiento y realice el ajuste <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\">Ver</a>.\n",
    "* Prediga los resultados para t de entrenamiento y t de pruebas. Usando accuracy_score determine la exactitud para t de entrenamiento y t de pruebas <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\">Ver</a>. \n",
    "* ¿Qué resultados obtuvo? Ahora puede modificar los parámetros que desee de la red neuronal. ¿Qué resultados obtuvo? Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion de activacion Sigmoidal con Gradiente Descendiente\n",
      "Exactitud Conjunto de entrenamiento: 0.3523809523809524\n",
      "Exactitud Conjunto de pruebas: 0.28888888888888886\n",
      "\n",
      "Funcion de activacion Tangente Hiperbolico con Solver Adam\n",
      "Exactitud Conjunto de entrenamiento: 0.9904761904761905\n",
      "Exactitud Conjunto de pruebas: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "print(\"Funcion de activacion Sigmoidal con Gradiente Descendiente\")\n",
    "\n",
    "transformer = Normalizer().fit(X)\n",
    "Xn = transformer.transform(X)\n",
    "\n",
    "Xe, Xp, ye, yp = train_test_split(Xn, t, test_size=0.3)\n",
    "\n",
    "clf = MLPClassifier(activation='logistic', solver='sgd', max_iter=20000)\n",
    "clf.fit(Xe, ye)\n",
    "\n",
    "pe = clf.predict(Xe)\n",
    "exacte = accuracy_score(ye, pe)\n",
    "print(\"Exactitud Conjunto de entrenamiento: \" + str(exacte))\n",
    "\n",
    "pp = clf.predict(Xp)\n",
    "exactp = accuracy_score(yp, pp)\n",
    "print(\"Exactitud Conjunto de pruebas: \" + str(exactp))\n",
    "\n",
    "print(\"\\nFuncion de activacion Tangente Hiperbolico con Solver Adam\")\n",
    "\n",
    "transformer = Normalizer().fit(X)\n",
    "Xn = transformer.transform(X)\n",
    "\n",
    "Xe, Xp, ye, yp = train_test_split(Xn, t, test_size=0.3)\n",
    "\n",
    "clf = MLPClassifier(activation='tanh', alpha=0.0002, max_iter=7500)\n",
    "clf.fit(Xe, ye)\n",
    "\n",
    "pe = clf.predict(Xe)\n",
    "exacte = accuracy_score(ye, pe)\n",
    "print(\"Exactitud Conjunto de entrenamiento: \" + str(exacte))\n",
    "\n",
    "pp = clf.predict(Xp)\n",
    "exactp = accuracy_score(yp, pp)\n",
    "print(\"Exactitud Conjunto de pruebas: \" + str(exactp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Cargue la base de datos y divida las etiquetas del conjunto de entrenamiento. Transforme las etiquetas (Letras) a números (0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Datasets/letter-recognition.data', names=np.arange(17)).to_numpy()\n",
    "X=data[:,1:16]\n",
    "t=data[:,0]\n",
    "\n",
    "for i, c in enumerate(t):\n",
    "    t[i] = ord(c) - 65\n",
    "    \n",
    "X=X.astype('int')\n",
    "t=t.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Siga los mismos pasos del punto 2, pero ahora en lugar de usar train_test_split use cross_val_score con un cv = 7 (<a href=\"https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics\">Ver</a>). ¿Qué resultados obtuvo? Interprete (2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion de activacion Sigmoidal con Gradiente Descendiente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.03875004806923341\n",
      "Funcion de activacion Tangente Hiperbolica con Gradiente Descendiente\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud: 0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:573: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "print(\"Funcion de activacion Sigmoidal con Gradiente Descendiente\")\n",
    "\n",
    "transformer = Normalizer().fit(X)\n",
    "Xn = transformer.transform(X)\n",
    "\n",
    "clf = MLPClassifier(activation='logistic', solver='sgd', max_iter=1000)\n",
    "clf.fit(Xn, t)\n",
    "\n",
    "scores = cross_val_score(clf, Xn, t, cv=7)\n",
    "exact = np.mean(scores)\n",
    "print(\"Exactitud: \" + str(exact))\n",
    "\n",
    "print(\"Funcion de activacion Tangente Hiperbolica con Gradiente Descendiente\")\n",
    "transformer = Normalizer().fit(X)\n",
    "Xn = transformer.transform(X)\n",
    "\n",
    "clf = MLPClassifier(activation='tanh', max_iter=5000) # Modifica solo los hiperparametros de aqui\n",
    "clf.fit(Xn, t)\n",
    "\n",
    "scores = cross_val_score(clf, Xn, t, cv=4) # Tambien puedes modificar el cv\n",
    "exact = np.mean(scores)\n",
    "print(\"Exactitud: \" + str(exact)) # Tiene que tener mejor exactidud que el de arriba, no cambies nada mas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
